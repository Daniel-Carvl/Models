# Models
# Carregar os pacotes necess√°rios
library(ggplot2)    # To plot locations
library(maps)       # To access useful maps
library(rasterVis)  # To plot raster objects
library(zeallot)
library(terra)
library(rJava)
library(kableExtra)
library(plotROC)
library(dismo)
library(raster)
library(sf)
library(rnaturalearth)
library(geodata)
library(reshape2)
library(SDMtune)
library(rnaturalearthdata)
library(spThin)
library(readxl)

# Converter coordenadas para num√©rico
Trips_palmi$lon <- as.numeric(as.character(Trips_palmi$lon))
Trips_palmi$lat <- as.numeric(as.character(Trips_palmi$lat))

# Preparar dados para thinning
xy <- data.frame(sp = "Trips", Trips_palmi)
xy_unique <- xy[!duplicated(xy[, c("lat", "lon")]), ]
cat("Registros originais:", nrow(xy), "\n")
cat("Ap√≥s remover duplicatas:", nrow(xy_unique), "\n")

# Thin points - remover pontos muito pr√≥ximos
distance = 1 # km
xy.t <- thin(loc.data = xy_unique, lat.col = "lat", long.col = "lon", spec.col = "sp",
             thin.par = distance, reps = 1, write.files = FALSE, 
             locs.thinned.list.return = TRUE)

xy.t <- data.frame(spp = "Trips", xy.t[[1]])
colnames(xy.t)[2:3] <- c("lon", "lat")
geo <- xy.t
cat("Registros finais:", nrow(geo), "\n")
# Converter para SpatialPoints
coordinates(geo) <- ~ lon + lat
crs(geo) <- "+proj=longlat +datum=WGS84"

# Carregar vari√°veis ambientais (WorldClim)
folder <- "C:/Users/Usu√°rio/Documents/Daniel/Artigo Adriano/WorldClim"
files <- list.files(folder, pattern = "\\.tif$", full.names = TRUE)
predictors <- rast(files)
names(predictors)
# Amostrar pontos aleat√≥rios por c√©lula (ajuste n conforme sua mem√≥ria)
set.seed(123) # para reproducibilidade
sample_points <- spatSample(predictors, size = 10000, method = "random", na.rm = TRUE)

# Remover quaisquer NAs restantes
sample_points <- na.omit(sample_points)

# Verificar a amostra
dim(sample_points)
head(sample_points)

# Padronizar os dados (muito importante para PCA)
scaled_data <- scale(sample_points)

# Verificar se a padroniza√ß√£o funcionou
summary(scaled_data)
apply(scaled_data, 2, mean) # M√©dias ‚âà 0
apply(scaled_data, 2, sd)   # Desvios padr√£o ‚âà 1

# Realizar a PCA
pca_result <- prcomp(scaled_data, center = FALSE, scale. = FALSE)

# Resumo detalhado
summary_pca <- summary(pca_result)
print(summary_pca)

# Definir n√∫mero de componentes
n_final_components <- 2

cat("=== USANDO PC1 E PC2 PARA MODELAGEM ===\n")
cat("PC1 explica:", round(51.4, 1), "% da vari√¢ncia\n")
cat("PC2 explica:", round(22.05, 1), "% da vari√¢ncia\n")
cat("TOTAL:", round(73.45, 1), "% da vari√¢ncia explicada\n")

# Loadings espec√≠ficos para PC1 e PC2
loadings_pc1_pc2 <- pca_result$rotation[, 1:2]
print("Loadings de PC1 e PC2:")
print(round(loadings_pc1_pc2, 3))

# Criar tabela mais leg√≠vel
loadings_table <- data.frame(
  Variable = rownames(loadings_pc1_pc2),
  PC1 = round(loadings_pc1_pc2[, 1], 3),
  PC2 = round(loadings_pc1_pc2[, 2], 3),
  Abs_PC1 = round(abs(loadings_pc1_pc2[, 1]), 3),
  Abs_PC2 = round(abs(loadings_pc1_pc2[, 2]), 3)
)

# Ordenar por import√¢ncia em PC1
loadings_table <- loadings_table[order(-loadings_table$Abs_PC1), ]
print("Vari√°veis ordenadas por import√¢ncia no PC1:")
print(loadings_table)

# Interpreta√ß√£o ecol√≥gica
cat("\n=== INTERPRETA√á√ÉO DOS COMPONENTES ===\n")

# PC1
cat("\nüìä PC1 (51.4% da vari√¢ncia) - Gradiente Principal:\n")
top_pc1_positive <- head(loadings_table[order(-loadings_table$PC1), ], 3)
top_pc1_negative <- head(loadings_table[order(loadings_table$PC1), ], 3)

cat("Principais contribui√ß√µes POSITIVAS:\n")
print(top_pc1_positive[, c("Variable", "PC1")])
cat("Principais contribui√ß√µes NEGATIVAS:\n") 
print(top_pc1_negative[, c("Variable", "PC1")])

# PC2
cat("\nüìä PC2 (22.1% da vari√¢ncia) - Gradiente Secund√°rio:\n")
top_pc2_positive <- head(loadings_table[order(-loadings_table$PC2), ], 3)
top_pc2_negative <- head(loadings_table[order(loadings_table$PC2), ], 3)

cat("Principais contribui√ß√µes POSITIVAS:\n")
print(top_pc2_positive[, c("Variable", "PC2")])
cat("Principais contribui√ß√µes NEGATIVAS:\n")
print(top_pc2_negative[, c("Variable", "PC2")])

# Vamos criar um dicion√°rio das vari√°veis para facilitar a interpreta√ß√£o
bio_vars <- data.frame(
  Variable = c(
    "wc2.1_5m_bio_1", "wc2.1_5m_bio_2", "wc2.1_5m_bio_3", 
    "wc2.1_5m_bio_4", "wc2.1_5m_bio_5", "wc2.1_5m_bio_6",
    "wc2.1_5m_bio_7", "wc2.1_5m_bio_8", "wc2.1_5m_bio_9",
    "wc2.1_5m_bio_10", "wc2.1_5m_bio_11", "wc2.1_5m_bio_12",
    "wc2.1_5m_bio_13", "wc2.1_5m_bio_14", "wc2.1_5m_bio_15",
    "wc2.1_5m_bio_16", "wc2.1_5m_bio_17", "wc2.1_5m_bio_18",
    "wc2.1_5m_bio_19"
  ),
  Description = c(
    "Temperatura M√©dia Anual",
    "Varia√ß√£o M√©dia Di√°ria (M√©dia mensal (max temp - min temp))",
    "Isotermalidade (BIO2/BIO7) √ó 100",
    "Sazonalidade da Temperatura (desvio padr√£o √ó 100)",
    "Temperatura M√°xima do M√™s Mais Quente",
    "Temperatura M√≠nima do M√™s Mais Frio",
    "Varia√ß√£o Anual da Temperatura (BIO5-BIO6)",
    "Temperatura M√©dia do Trimestre Mais Chuvoso",
    "Temperatura M√©dia do Trimestre Mais Seco",
    "Temperatura M√©dia do Trimestre Mais Quente",
    "Temperatura M√©dia do Trimestre Mais Frio",
    "Precipita√ß√£o Anual",
    "Precipita√ß√£o do M√™s Mais Chuvoso",
    "Precipita√ß√£o do M√™s Mais Seco",
    "Sazonalidade da Precipita√ß√£o (Coeficiente de Varia√ß√£o)",
    "Precipita√ß√£o do Trimestre Mais Chuvoso",
    "Precipita√ß√£o do Trimestre Mais Seco",
    "Precipita√ß√£o do Trimestre Mais Quente",
    "Precipita√ß√£o do Trimestre Mais Frio"
  )
)

print(bio_vars)
library(vegan)
library(factoextra)
# Biplot dos dois primeiros componentes
fviz_pca_biplot(pca_result, 
                axes = c(1, 2),
                col.var = "contrib",
                gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
                repel = TRUE,
                title = "Biplot - PC1 vs PC2")

# Gr√°fico apenas das vari√°veis nos dois primeiros componentes
fviz_pca_var(pca_result, 
             axes = c(1, 2),
             col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,
             title = "Vari√°veis nos Dois Primeiros Componentes")

# Fun√ß√£o otimizada para 2 componentes
create_pc1_pc2_raster <- function(raster_data, pca_model) {
  # Extrair estat√≠sticas de padroniza√ß√£o
  center_vals <- attr(scaled_data, "scaled:center")
  scale_vals <- attr(scaled_data, "scaled:scale")
  
  # Fun√ß√£o para aplicar PCA
  pca_fun <- function(x) {
    # Padronizar
    x_scaled <- scale(x, center = center_vals, scale = scale_vals)
    # Aplicar transforma√ß√£o PCA e manter apenas PC1 e PC2
    pca_scores <- x_scaled %*% pca_model$rotation
    return(pca_scores[, 1:2])
  }
  
  # Aplicar ao raster
  pc_raster <- app(raster_data, pca_fun)
  names(pc_raster) <- c("PC1", "PC2")
  
  return(pc_raster)
}

# Criar raster com PC1 e PC2
cat("Criando raster com PC1 e PC2...\n")
pc12_predictors <- create_pc1_pc2_raster(predictors, pca_result)

# Verificar resultado
print(pc12_predictors)
cat("Dimens√µes do raster PCA:", dim(pc12_predictors), "\n")

# Plotar os dois componentes lado a lado
par(mfrow = c(1, 2))
plot(pc12_predictors$PC1, 
     main = paste("PC1 (", round(51.4, 1), "%)"),
     col = colorRampPalette(c("blue", "white", "red"))(100))
plot(pc12_predictors$PC2, 
     main = paste("PC2 (", round(22.1, 1), "%)"),
     col = colorRampPalette(c("darkgreen", "lightgreen", "yellow"))(100))
par(mfrow = c(1, 1))

# Plot conjunto
plot(pc12_predictors, 
     main = "Componentes Principais 1 e 2 para Modelagem")

# Salvar raster com apenas PC1 e PC2
writeRaster(pc12_predictors, 
            filename = "worldclim_pc1_pc2.tif",
            overwrite = TRUE,
            filetype = "GTiff")

# Salvar vers√£o compactada se necess√°rio
writeRaster(pc12_predictors, 
            filename = "worldclim_pc1_pc2_compressed.tif",
            overwrite = TRUE,
            gdal = c("COMPRESS=DEFLATE"))

# Salvar metadados importantes
pca_metadata <- list(
  n_components = 2,
  variance_explained = summary_pca$importance[2, 1:2],
  cumulative_variance = summary_pca$importance[3, 2],
  loadings = loadings_pc1_pc2,
  scaling_center = attr(scaled_data, "scaled:center"),
  scaling_scale = attr(scaled_data, "scaled:scale")
)

saveRDS(pca_metadata, file = "pca_pc1_pc2_metadata.rds")

# Salvar tabela de loadings em CSV
write.csv(loadings_table, 
          file = "pc1_pc2_loadings.csv", 
          row.names = FALSE)

cat("\n=== ARQUIVOS SALVOS ===\n")
cat("‚úÖ worldclim_pc1_pc2.tif - Raster com PC1 e PC2 para modelagem\n")
cat("‚úÖ pca_pc1_pc2_metadata.rds - Metadados da PCA\n")
cat("‚úÖ pc1_pc2_loadings.csv - Tabela de loadings\n")



# VERIFICA√á√ïES INICIAIS ====================================================
print("=== VERIFICA√á√ïES INICIAIS ===")
print(paste("N√∫mero de presen√ßas ap√≥s thinning:", nrow(geo)))
print("Extens√£o dos predictors:")
print(ext(pc12_predictors))

# CONFIGURA√á√ÉO OTIMIZADA PARA MODELAGEM ===================================
set.seed(123)

# N√∫mero otimizado de pseudo-aus√™ncias (ratio 5:1)
n_presencas <- nrow(geo)
n_pseudo_optimizado <- n_presencas * 5  # Ratio 5:1
print(paste("N√∫mero de presen√ßas:", n_presencas))
print(paste("N√∫mero otimizado de pseudo-aus√™ncias:", n_pseudo_optimizado))

# CONVERTER SpatRaster global para RasterLayer
mask_raster_raster <- raster(pc12_predictors[[1]])
mask_raster_raster[!is.na(mask_raster_raster)] <- 1

# Gerar pseudo-aus√™ncias em TODO o mundo
pseudo_ausencias <- randomPoints(mask_raster_raster, n = n_pseudo_optimizado)

# Converter para dataframe
pseudo_ausencias_df <- data.frame(pseudo_ausencias)
colnames(pseudo_ausencias_df) <- c("lon", "lat")

# CRIAR presencas_df (que estava faltando)
presencas_df <- data.frame(geo)[, c("lon", "lat")]

# Adicionar coluna de presen√ßa/aus√™ncia
pseudo_ausencias_df$presence <- 0
presencas_df$presence <- 1

# Combinar presen√ßas e pseudo-aus√™ncias
occ_data <- rbind(presencas_df, pseudo_ausencias_df)

print(paste("‚úÖ Total de pontos:", nrow(occ_data)))
print(paste("‚úÖ Presen√ßas:", sum(occ_data$presence)))
print(paste("‚úÖ Pseudo-aus√™ncias:", sum(occ_data$presence == 0)))
print(paste("‚úÖ Ratio final:", round(n_pseudo_optimizado/n_presencas, 1), ":1"))

par(mfrow=c(1,1))
# PLOT DOS DADOS FINAIS ====================================================
plot(predictors[[1]], main = paste("Distribui√ß√£o de Trips palmi\n",
                                   "Presen√ßas:", n_presencas, 
                                   "Pseudo-aus√™ncias:", n_pseudo_optimizado))

# Adicionar mapa mundial
map('world', add = TRUE, col = "gray80", fill = TRUE)

# Plotar pseudo-aus√™ncias
points(occ_data$lon[occ_data$presence == 0], 
       occ_data$lat[occ_data$presence == 0], 
       col = adjustcolor("blue", alpha.f = 0.2), 
       pch = 16, cex = 0.3)

# Plotar presen√ßas
points(occ_data$lon[occ_data$presence == 1], 
       occ_data$lat[occ_data$presence == 1], 
       col = "red", pch = 16, cex = 0.8)

legend("bottomleft", 
       legend = c(paste("Presen√ßas (", n_presencas, ")"), 
                  paste("Pseudo-aus√™ncias (", n_pseudo_optimizado, ")")),
       col = c("red", adjustcolor("blue", alpha.f = 0.6)), 
       pch = 16, cex = 0.8, bg = "white")

# Carregar pacotes necess√°rios
library(sdm)
library(raster)
library(terra)

# Preparar dados no formato do pacote sdm
# Usando seus dados j√° processados:
# occ_data tem presen√ßas (1) e pseudo-aus√™ncias (0)
# predictors s√£o suas vari√°veis ambientais

# Converter para formato sdmData
spp <- "Trips_palmi"

# Preparar dados de presen√ßa
presencas <- occ_data[occ_data$presence == 1, c("lon", "lat")]
presencas$species <- 1  # Adicionar coluna da esp√©cie

# Preparar dados de background (pseudo-aus√™ncias)
background <- occ_data[occ_data$presence == 0, c("lon", "lat")]

# 1. Criar dataframe com coordenadas
sdm_train_data <- data.frame(
  species = occ_data$presence,
  x = occ_data$lon,
  y = occ_data$lat
)

# 2. Criar sdmData com coords() na f√≥rmula - FORMA CORRETA
my.sdm.data <- sdmData(
  formula = species ~ . + coords(x + y),  # AQUI EST√Å A CHAVE!
  train = sdm_train_data,
  predictors = pc12_predictors
)

print(my.sdm.data)

# Verificar o resumo dos dados
summary(my.sdm.data)

# Verificar quais m√©todos est√£o dispon√≠veis
getmethodNames()

# maxnet √© uma implementa√ß√£o moderna em R puro
available_models <- c("glm", "maxnet", "rf")

my.sdm.out2 <- sdm(
  formula = species ~ .,
  data = my.sdm.data,
  methods = available_models,
  replication = 'cv',
  cv.folds = 5,
  n = 10
)

# Ver se todos os modelos funcionaram
print(my.sdm.out2)
summary(my.sdm.out2)

cat("\n=== NOVO MODELO (com maxnet) ===\n") 
print(my.sdm.out2)

# Ensemble final com todos os 6 algoritmos funcionando
ensemble_global <- ensemble(
  my.sdm.out2, 
  newdata = pc12_predictors,
  filename = "Trips_palmi_global_ensemble_final.tif",
  setting = list(
    method = 'weighted', 
    stat = 'AUC', 
    opt = 2
  ),
  overwrite = TRUE
)

# Configurar plot para tela cheia
par(mar = c(4, 4, 4, 6))  # Margens maiores para a legenda

# Plotar o mapa em alta qualidade
plot(ensemble_global, 
     main = "Global Potential Distribution - Trips palmi",
     col = colorRampPalette(c("blue", "cyan", "yellow", "red"))(100),
     axes = TRUE,
     plg = list(size = c(1, 1.5), # Legenda maior
                title = "Suitability"),
     cex.main = 1.2,
     smooth = TRUE)  # Suaviza as cores

# Adicionar continentes com mais detalhes
library(maps)
map('world', add = TRUE, col = "gray20", fill = FALSE, lwd = 0.5)

# Adicionar pontos de ocorr√™ncia
points(occ_data$lon[occ_data$presence == 1], 
       occ_data$lat[occ_data$presence == 1], 
       col = "black", pch = 21, bg = "white", cex = 0.8, lwd = 0.1)

# Legenda detalhada
legend("bottomleft",
       legend = c("Alta adequabilidade", "Baixa adequabilidade", "Registros de ocorr√™ncia"),
       fill = c("red", "blue", NA),
       border = c(NA, NA, "black"),
       pch = c(NA, NA, 21),
       pt.bg = c(NA, NA, "white"),
       bg = "white", 
       cex = 0.8)
# Tabela de avalia√ß√£o completa
eval_results <- getEvaluation(my.sdm.out2)
write.csv(eval_results, "Trips_palmi_model_evaluation_FINAL.csv", row.names = FALSE)

# Carregar o dplyr
library(dplyr)

# Agora sim, calcular as estat√≠sticas resumidas
performance_summary <- eval_results %>%
  mutate(algorithm = case_when(
    modelID <= 50 ~ "glm",
    modelID <= 100 ~ "maxnet", 
    modelID <= 150 ~ "rf"
  )) %>%
  group_by(algorithm) %>%
  summarise(
    AUC_mean = round(mean(AUC), 3),
    AUC_sd = round(sd(AUC), 3),
    TSS_mean = round(mean(TSS), 3),
    TSS_sd = round(sd(TSS), 3),
    n_models = n()
  ) %>%
  arrange(desc(AUC_mean))

print(performance_summary)
# Carregar pacote para exportar HTML
library(knitr)
library(webshot)

# Salvar como HTML formatado
html_table <- performance_summary %>%
  knitr::kable(format = "html", digits = 3,
               caption = "Performance of Modeling Algorithms - Trips palmi",
               col.names = c("Algorithm", "Average AUC", "AUC SD", "Average TSS", "TSS SD", "N¬∞ Models")) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                            full_width = FALSE,
                            font_size = 14)

# Salvar arquivo HTML
writeLines(html_table, "Trips_palmi_performance_table.html")

# An√°lise de quais vari√°veis ambientais s√£o mais importantes
var_imp <- getVarImp(my.sdm.out2)
plot(var_imp, main = "Importance of Variables - Trips palmi")

# Salvar tabela
var_imp_table <- var_imp@varImportanceMean
write.table(var_imp_table, "Trips_palmi_variable_importance.txt")
html_table <- var_imp_table %>%
  knitr::kable(format = "html", digits = 3,
               caption = "Importance of Variables - Trips palmi",
               col.names = c("Axes", "variables", "corTest", "lower", "upper")) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                            full_width = FALSE,
                            font_size = 14)
# Salvar arquivo HTML
writeLines(html_table, "Importance of Variables - Trips palmi.html")

# Calcular threshold
# M√©todo 1: Threshold para o ENSEMBLE (recomendado)
thresholds <- sdm::threshold(my.sdm.out2, id = "ensemble")
print(thresholds)

# Criar mapa bin√°rio CORRETAMENTE
binary_map <- ensemble_global > thresholds

par(mfrow = c(1, 2))
# Plotar
plot(binary_map, 
     main = paste("Suitable Areas - Trips palmi\nThreshold =", round(thresholds, 3)),
     col = c("lightgray", "darkgreen"))

# Adicionar continentes
map('world', add = TRUE, col = "gray30", lwd = 0.6)

# Legenda
legend("bottomleft",
       legend = c(paste("N√£o Adequado (<", round(thresholds, 3), ")"), 
                  paste("Adequado (‚â•", round(thresholds, 3), ")")),
       fill = c("lightgray", "darkgreen"),
       bg = "white")

# Salvar
writeRaster(binary_map, "Trips_palmi_binary_map.tif", overwrite = TRUE)
cat("‚úÖ Mapa bin√°rio salvo com threshold de", thresholds, "\n")